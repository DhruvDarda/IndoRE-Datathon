{"cells":[{"cell_type":"code","execution_count":null,"id":"dae73f4f","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:14:58.776670Z","iopub.status.busy":"2021-12-06T16:14:58.775153Z","iopub.status.idle":"2021-12-06T16:15:01.693838Z","shell.execute_reply":"2021-12-06T16:15:01.692959Z","shell.execute_reply.started":"2021-12-06T16:07:33.814790Z"},"id":"dae73f4f","papermill":{"duration":2.938237,"end_time":"2021-12-06T16:15:01.693993","exception":false,"start_time":"2021-12-06T16:14:58.755756","status":"completed"},"tags":[]},"outputs":[],"source":["import gc\n","import sys\n","# This line is required for the framework that I have created. In this notebook, \n","# I'd rather place all my functions here itself.\n","# sys.path.append(\"./src\")\n","import json\n","import math\n","import os\n","from abc import ABC, abstractmethod\n","from collections import OrderedDict\n","from random import randint, sample\n","from typing import Iterable, Tuple\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","from pandas import DataFrame\n","\n","from matplotlib.figure import Figure\n","from sklearn.metrics import *\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","from sklearn.utils import column_or_1d\n","from torch import Tensor, nn\n","from torch.nn import functional as F\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import LambdaLR\n","from torch.utils.data import DataLoader, IterableDataset\n","from tqdm.auto import tqdm\n","import transformers\n","import datasets"]},{"cell_type":"code","execution_count":null,"id":"9ff165d6","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:01.730354Z","iopub.status.busy":"2021-12-06T16:15:01.728737Z","iopub.status.idle":"2021-12-06T16:15:01.730910Z","shell.execute_reply":"2021-12-06T16:15:01.731321Z","shell.execute_reply.started":"2021-12-06T16:07:36.723534Z"},"id":"9ff165d6","papermill":{"duration":0.021324,"end_time":"2021-12-06T16:15:01.731466","exception":false,"start_time":"2021-12-06T16:15:01.710142","status":"completed"},"tags":[]},"outputs":[],"source":["class Config:\n","    def __init__(self):\n","        self.SEED = 1996\n","        self.MODEL_INDEX = 0\n","        self.BS = 8\n","        self.EPOCH = 10\n","\n","config = Config()"]},{"cell_type":"code","execution_count":null,"id":"e6f52822","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:01.766434Z","iopub.status.busy":"2021-12-06T16:15:01.765845Z","iopub.status.idle":"2021-12-06T16:15:01.771880Z","shell.execute_reply":"2021-12-06T16:15:01.771449Z","shell.execute_reply.started":"2021-12-06T16:07:36.730128Z"},"id":"e6f52822","papermill":{"duration":0.026697,"end_time":"2021-12-06T16:15:01.771988","exception":false,"start_time":"2021-12-06T16:15:01.745291","status":"completed"},"tags":[]},"outputs":[],"source":["def replacer(sentence):\n","    res = sentence.replace(\"<e1>\", \"[\")\n","    res = res.replace(\"</e1>\", \"]\")\n","    res = res.replace(\"<e2>\", \"{\")\n","    res = res.replace(\"</e2>\", \"}\")\n","    return res\n","\n","def set_random_seed(seed, deterministic=False):\n","    \"\"\"Set random seed.\n","\n","    Args:\n","        seed (int): Seed to be used.\n","        deterministic (bool): Whether to set the deterministic option for\n","            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n","            to True and `torch.backends.cudnn.benchmark` to False.\n","            Default: False.\n","    \"\"\"\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    if deterministic:\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","\n","set_random_seed(config.SEED)"]},{"cell_type":"code","execution_count":null,"id":"8287fc5a","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:01.835045Z","iopub.status.busy":"2021-12-06T16:15:01.834267Z","iopub.status.idle":"2021-12-06T16:15:01.836593Z","shell.execute_reply":"2021-12-06T16:15:01.836998Z","shell.execute_reply.started":"2021-12-06T16:07:36.742452Z"},"id":"8287fc5a","papermill":{"duration":0.051179,"end_time":"2021-12-06T16:15:01.837132","exception":false,"start_time":"2021-12-06T16:15:01.785953","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import numpy as np\n","from torch import nn\n","import time\n","import datetime\n","from tqdm import tqdm\n","from sklearn import metrics\n","import torch.multiprocessing as mp\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","class F1Meter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.y_true = np.array([0, 1])\n","        self.y_pred = np.array([0, 1])\n","        self.score = 0\n","\n","    def update(self, y_true, y_pred):\n","        # print(f\"y_true = {y_true}, y_pred = {y_pred}\")\n","        y_true = y_true.cpu().numpy()\n","        # y_pred = y_pred.detach().cpu().numpy()\n","        y_pred = nn.functional.softmax(y_pred, dim=1).argmax(axis=1).data.cpu().numpy()\n","        self.y_true = np.hstack((self.y_true, y_true))\n","        self.y_pred = np.hstack((self.y_pred, y_pred))\n","        # print(f\"y_true = {self.y_true}, y_pred = {self.y_pred}\")\n","        self.score = metrics.f1_score(self.y_true, self.y_pred, average=\"micro\")\n","        # print(self.score)\n","        # exit()\n","\n","    @property\n","    def avg(self):\n","        return self.score\n","\n","class RocAucMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.y_true = np.array([0, 1])\n","        self.y_pred = np.array([0.5, 0.5])\n","        self.score = 0\n","\n","    def update(self, y_true, y_pred):\n","        # print(f\"y_true = {y_true}, y_pred = {y_pred}\")\n","        y_true = y_true.cpu().numpy()\n","        y_pred = y_pred.data.cpu().numpy()[:, 1]\n","        # print(f\"y_true = {y_true}, y_pred = {y_pred}\")\n","        # exit()\n","        self.y_true = np.hstack((self.y_true, y_true))\n","        self.y_pred = np.hstack((self.y_pred, y_pred))\n","        self.score = self.y_true/len(self.y_true)\n","\n","    @property\n","    def avg(self):\n","        return self.score\n","\n","def train_loop_fn(\n","    data_loader,\n","    model,\n","    optimizer,\n","    device,\n","    scheduler=None,\n","    epoch=None,\n","    wandb=None,\n","    scaler=None,\n","    validation_dl=None,\n","):\n","\n","    model.train()\n","    losses = AverageMeter()\n","    f1score = F1Meter()\n","    auc = AverageMeter()\n","    start_time = time.time()\n","    total_batches = len(data_loader)\n","    progress = tqdm(data_loader, leave=True, disable=False)\n","    progress.set_description(f\"{epoch}\")\n","    val_auc = 0\n","    val_f1 = 0\n","    for bi, d in enumerate(progress):\n","\n","        ids = d[\"input_ids\"]\n","        targets = d[\"labels\"]\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        # mask = mask.to(device, dtype=torch.long)\n","        targets = targets.to(device, dtype=torch.float)\n","\n","        optimizer.zero_grad()\n","\n","        if type(scaler) != type(None):\n","            with torch.cuda.amp.autocast():\n","                logits = model(input_ids=ids)\n","                outputs = logits.softmax(dim=1)\n","                # print(dir(outputs))\n","                # print(outputs, targets)\n","                # print(outputs.dtype, targets.dtype)\n","                loss = torch.nn.functional.cross_entropy(\n","                    outputs.to(torch.float), targets.to(torch.long)\n","                )\n","                # loss = outputs.loss\n","            scaler.scale(loss).backward()\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n","            scaler.step(optimizer)\n","            scaler.update()\n","            # optimizer.zero_grad()\n","        else:\n","            outputs = model(input_ids=ids)\n","\n","            loss = loss_fn(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","        loss_val = loss.detach().item()\n","        auc.update(\n","            torch.sum(outputs.argmax(axis=1).detach() == targets.detach()), ids.size(0)\n","        )\n","        f1score.update(targets, outputs)\n","        losses.update(loss_val, ids.size(0))\n","\n","        if bi % 100000 == 0 and bi != 0:\n","            f1score.reset()\n","            # auc.reset()\n","            if type(validation_dl) != type(None):\n","                o, t = eval_loop_fn(validation_dl, model, device)\n","                y_true = np.array(t)\n","                y_pred = o\n","                # # val_auc = metrics.roc_auc_score(y_true, y_pred)\n","                val_f1 = metrics.f1_score(y_true, y_pred)\n","                # wandb.log({})\n","                print(f\"epoch={epoch}, F1 = {val_f1}\")\n","                model.train()\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        progress.set_postfix(\n","            {\n","                \"Loss\": f\"{losses.avg:<8.4f}\",\n","                \"ACC\": f\"{auc.avg:<8.4f}\",\n","                \"F1\": f\"{f1score.avg:<8.4f}\",\n","            }\n","        )\n","\n","    del loss\n","    del losses\n","    del outputs\n","    del ids\n","    del targets\n","    model.eval()\n","\n","\n","def eval_loop_fn(data_loader, model, device):\n","\n","    model.eval()\n","    fin_targets = []\n","    fin_outputs = []\n","    fin_index = []\n","    with torch.no_grad():\n","        pbar = tqdm(data_loader, leave=False, disable=False)\n","        for bi, d in enumerate(pbar):\n","\n","            # if bi % 100 == 0:\n","            #     print(f'EVAL bi={bi}')\n","\n","            ids = d[\"input_ids\"]\n","            targets = d[\"labels\"]\n","\n","            ids = ids.to(device, dtype=torch.long)\n","            targets = targets.to(device, dtype=torch.float)\n","\n","            logits = model(input_ids=ids)\n","            outputs = logits.softmax(dim=1)\n","\n","            targets_np = targets.cpu().detach().numpy().tolist()\n","            # targets_np = targets.cpu().detach().numpy().tolist()\n","            outputs_np = outputs.cpu().detach().numpy().argmax(axis=1).tolist()\n","\n","            fin_targets.extend(targets_np)\n","            fin_outputs.extend(outputs_np)\n","\n","    return fin_outputs, fin_targets\n","\n","\n","def pred_loop_fn(data_loader, model, device):\n","\n","    # model.eval()\n","    fin_ids = []\n","    fin_outputs = []\n","    fin_index = []\n","    with torch.no_grad():\n","        pbar = tqdm(data_loader, leave=False, disable=False)\n","        for bi, d in enumerate(pbar):\n","\n","            # if bi % 100 == 0:\n","            #     print(f'EVAL bi={bi}')\n","\n","            ids = d[\"input_ids\"]\n","            idx = d[\"ids\"]\n","\n","            ids = ids.to(device, dtype=torch.long)\n","\n","            logits = model(input_ids=ids)\n","            outputs = logits.softmax(dim=1)\n","\n","            outputs_np = outputs.cpu().detach().numpy().argmax(axis=1).tolist()\n","\n","            fin_ids.extend(idx.cpu().detach().numpy().tolist())\n","            fin_outputs.extend(outputs_np)\n","\n","    return fin_outputs, fin_ids"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","\n","%cd /content/gdrive/My Drive/Kaggle\n","path = %pwd"],"metadata":{"id":"q8PrvZqpwnKz"},"id":"q8PrvZqpwnKz","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"6590f3df","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:01.872622Z","iopub.status.busy":"2021-12-06T16:15:01.872079Z","iopub.status.idle":"2021-12-06T16:15:02.548780Z","shell.execute_reply":"2021-12-06T16:15:02.549407Z","shell.execute_reply.started":"2021-12-06T16:07:36.781159Z"},"id":"6590f3df","outputId":"511959b2-21fb-463c-c46b-1a8aadb05261","papermill":{"duration":0.698613,"end_time":"2021-12-06T16:15:02.549582","exception":false,"start_time":"2021-12-06T16:15:01.850969","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["NO_LABELS:  25\n","(12051, 4)\n","(1340, 4)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Relation</th>\n","      <th>Sentence</th>\n","      <th>NER1</th>\n","      <th>NER2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>12046</th>\n","      <td>director</td>\n","      <td>[ভয়ংকর সুন্দর] {অনিমেষ আইচ} পরিচালিত ২০১৭ সাল...</td>\n","      <td>WORK_OF_ART</td>\n","      <td>PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>12047</th>\n","      <td>parent_organization</td>\n","      <td>{The Walt Disney Company} acquired the parent ...</td>\n","      <td>ORG</td>\n","      <td>ORG</td>\n","    </tr>\n","    <tr>\n","      <th>12048</th>\n","      <td>subsidiary</td>\n","      <td>RV \"Pelagia\" is a research vessel in the servi...</td>\n","      <td>ORG</td>\n","      <td>ORG</td>\n","    </tr>\n","    <tr>\n","      <th>12049</th>\n","      <td>child</td>\n","      <td>{హర్ష్ వర్ధన్ కపూర్} భారతీయ నటుడు. ప్రముఖ కపూర...</td>\n","      <td>PERSON</td>\n","      <td>PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>12050</th>\n","      <td>position_held</td>\n","      <td>बता दें कि [जसवंत सिंह] भारतीय राजनीति के उन थ...</td>\n","      <td>PERSON</td>\n","      <td>OTHER</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  Relation                                           Sentence  \\\n","12046             director  [ভয়ংকর সুন্দর] {অনিমেষ আইচ} পরিচালিত ২০১৭ সাল...   \n","12047  parent_organization  {The Walt Disney Company} acquired the parent ...   \n","12048           subsidiary  RV \"Pelagia\" is a research vessel in the servi...   \n","12049                child  {హర్ష్ వర్ధన్ కపూర్} భారతీయ నటుడు. ప్రముఖ కపూర...   \n","12050        position_held  बता दें कि [जसवंत सिंह] भारतीय राजनीति के उन थ...   \n","\n","              NER1    NER2  \n","12046  WORK_OF_ART  PERSON  \n","12047          ORG     ORG  \n","12048          ORG     ORG  \n","12049       PERSON  PERSON  \n","12050       PERSON   OTHER  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["ROOT_DIR = os.path.abspath(\"./datathon\")\n","\n","df = [\n","    pd.read_csv(\"train.tsv\", delimiter=\"\\t\"),\n","    pd.read_csv(\"en.tsv\", delimiter=\"\\t\"),\n","]\n","\n","df = pd.concat(df)\n","\n","df.Sentence = df.Sentence.apply(lambda x: replacer(x))\n","df.to_csv(\"processsed.csv\", sep=\"\\t\")\n","df = df.sample(frac=1)\n","NO_LABELS = len(df.Relation.value_counts())\n","print(\"NO_LABELS: \", NO_LABELS)\n","df.reset_index(drop=True, inplace=True)\n","train_df, valid_df = train_test_split(\n","    df, test_size=0.1, shuffle=True, random_state=config.SEED\n",")\n","train_df.reset_index(drop=True, inplace=True)\n","valid_df.reset_index(drop=True, inplace=True)\n","# print(train_df.tail())\n","print(train_df.shape)\n","print(valid_df.shape)\n","test_df = pd.read_csv(\"../input/indore-datathon-2021/valid.tsv\", delimiter=\"\\t\")\n","test_df.Sentence = test_df.Sentence.apply(lambda x: replacer(x))\n","train_df.tail()"]},{"cell_type":"code","execution_count":null,"id":"4a0ae3c7","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:02.585344Z","iopub.status.busy":"2021-12-06T16:15:02.584536Z","iopub.status.idle":"2021-12-06T16:15:02.587393Z","shell.execute_reply":"2021-12-06T16:15:02.586920Z","shell.execute_reply.started":"2021-12-06T16:07:37.498169Z"},"id":"4a0ae3c7","papermill":{"duration":0.022251,"end_time":"2021-12-06T16:15:02.587516","exception":false,"start_time":"2021-12-06T16:15:02.565265","status":"completed"},"tags":[]},"outputs":[],"source":["# --- Subject & object markup ---\n","SUB_START_CHAR = \"[\"\n","SUB_END_CHAR = \"]\"\n","OBJ_START_CHAR = \"{\"\n","OBJ_END_CHAR = \"}\""]},{"cell_type":"code","execution_count":null,"id":"a86e82c3","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:02.622091Z","iopub.status.busy":"2021-12-06T16:15:02.621288Z","iopub.status.idle":"2021-12-06T16:15:02.623534Z","shell.execute_reply":"2021-12-06T16:15:02.623930Z","shell.execute_reply.started":"2021-12-06T16:07:37.504220Z"},"id":"a86e82c3","papermill":{"duration":0.021866,"end_time":"2021-12-06T16:15:02.624068","exception":false,"start_time":"2021-12-06T16:15:02.602202","status":"completed"},"tags":[]},"outputs":[],"source":["# --- BERT variants ---\n","# See https://huggingface.co/transformers/pretrained_models.html for the full list\n","AVAILABLE_PRETRAINED_MODELS = [\n","    \"xlm-roberta-base\",  # 0\n","    \"xlm-roberta-large\",  # 1\n","    \"bert-base-uncased\",  # 2\n","    \"bert-base-multilingual-cased\",  # 3\n","    \"gpt2\",  # 4\n","    \"distilroberta-base\",  # 5\n","    \"roberta-base\",  # 6\n","    \"albert-base-v1\",  # 7\n","    \"albert-base-v2\",  # 8\n","    \"bert-large-uncased\",  # 9\n","]"]},{"cell_type":"code","execution_count":null,"id":"9103211f","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:02.661566Z","iopub.status.busy":"2021-12-06T16:15:02.660987Z","iopub.status.idle":"2021-12-06T16:15:02.664500Z","shell.execute_reply":"2021-12-06T16:15:02.664883Z","shell.execute_reply.started":"2021-12-06T16:07:37.513915Z"},"id":"9103211f","papermill":{"duration":0.025978,"end_time":"2021-12-06T16:15:02.665022","exception":false,"start_time":"2021-12-06T16:15:02.639044","status":"completed"},"tags":[]},"outputs":[],"source":["class IndoML(nn.Module):\n","    def __init__(self, name) -> None:\n","        super(IndoML, self).__init__()\n","        self.num_labels = NO_LABELS\n","        self.roberta = transformers.AutoModel.from_pretrained(\n","            name,\n","            output_hidden_states=False,\n","            num_labels=NO_LABELS,\n","            cache_dir=\"/tmp/cache/\",\n","        )\n","        self.outlayer = self.roberta.pooler.dense.out_features\n","        self.dropout = nn.Dropout(p=0.4)\n","        self.ln = nn.LayerNorm(self.outlayer)\n","        self.classifier = nn.Linear(self.outlayer, self.num_labels)\n","\n","    def forward(self, input_ids=None):\n","\n","        out = self.roberta(input_ids)\n","        x1 = torch.mean(out.last_hidden_state, 1)\n","\n","        x = x1\n","\n","        x = self.ln(x)\n","        x = self.dropout(x)\n","\n","        logits = self.classifier(x)\n","        return logits"]},{"cell_type":"code","execution_count":null,"id":"fb233ea7","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:02.701644Z","iopub.status.busy":"2021-12-06T16:15:02.700796Z","iopub.status.idle":"2021-12-06T16:15:02.702852Z","shell.execute_reply":"2021-12-06T16:15:02.703255Z","shell.execute_reply.started":"2021-12-06T16:07:37.524761Z"},"id":"fb233ea7","papermill":{"duration":0.023281,"end_time":"2021-12-06T16:15:02.703419","exception":false,"start_time":"2021-12-06T16:15:02.680138","status":"completed"},"tags":[]},"outputs":[],"source":["LAB2ID = {\n","    \"director\": 0,\n","    \"child\": 1,\n","    \"spouse\": 2,\n","    \"sport\": 3,\n","    \"father\": 4,\n","    \"award_received\": 5,\n","    \"mother\": 6,\n","    \"position_held\": 7,\n","    \"sibling\": 8,\n","    \"original_language_of_film_or_TV_show\": 9,\n","    \"employer\": 10,\n","    \"occupation\": 11,\n","    \"parent_organization\": 12,\n","    \"capital\": 13,\n","    \"discoverer_or_inventor\": 14,\n","    \"founded_by\": 15,\n","    \"participant\": 16,\n","    \"tributary\": 17,\n","    \"subsidiary\": 18,\n","    \"winner\": 19,\n","    \"capital_of\": 20,\n","    \"place_of_birth\": 21,\n","    \"place_of_death\": 22,\n","    \"student_of\": 23,\n","    \"nominated_for\": 24,\n","}\n","\n","ID2LAB = list(LAB2ID.keys())"]},{"cell_type":"code","execution_count":null,"id":"dbb64a39","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:02.746443Z","iopub.status.busy":"2021-12-06T16:15:02.744842Z","iopub.status.idle":"2021-12-06T16:15:02.747000Z","shell.execute_reply":"2021-12-06T16:15:02.747431Z","shell.execute_reply.started":"2021-12-06T16:07:37.538988Z"},"id":"dbb64a39","papermill":{"duration":0.02923,"end_time":"2021-12-06T16:15:02.747564","exception":false,"start_time":"2021-12-06T16:15:02.718334","status":"completed"},"tags":[]},"outputs":[],"source":["class IndoMLDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenizer, X, y=None) -> None:\n","        self.label2id = LAB2ID\n","        self.X = X.astype(str)\n","        self.y = y\n","        self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n","            tokenizer, cache_dir=\"/tmp/cache/\"\n","        )\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        txt = self.X.iloc[idx]\n","        tokenized = self.tokenizer.encode_plus(\n","            txt,\n","            return_attention_mask=False,\n","            return_token_type_ids=False,\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=196,\n","            return_tensors=\"pt\",\n","        )[\"input_ids\"].view(-1)\n","        if type(self.y) != type(None):\n","            lab = torch.tensor(self.label2id[self.y.iloc[idx]], dtype=torch.long)\n","        else:\n","            lab = torch.tensor(0, dtype=torch.long)\n","        return {\n","            # \"text\": txt,\n","            \"input_ids\": tokenized,\n","            \"labels\": lab,\n","        }\n","\n","class IndoMLTestDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenizer, X, idx) -> None:\n","        self.label2id = LAB2ID\n","        self.X = X.astype(str)\n","        self.y = idx\n","        self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n","            tokenizer, cache_dir=\"/tmp/cache/\"\n","        )\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        txt = self.X.iloc[idx]\n","        tokenized = self.tokenizer.encode_plus(\n","            txt,\n","            return_attention_mask=False,\n","            return_token_type_ids=False,\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=196,\n","            return_tensors=\"pt\",\n","        )[\"input_ids\"].view(-1)\n","\n","        return {\n","            \"input_ids\": tokenized,\n","            \"ids\": self.y.iloc[idx],\n","        }"]},{"cell_type":"code","execution_count":null,"id":"eec3ddf6","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:02.784553Z","iopub.status.busy":"2021-12-06T16:15:02.783893Z","iopub.status.idle":"2021-12-06T16:15:25.439866Z","shell.execute_reply":"2021-12-06T16:15:25.439358Z","shell.execute_reply.started":"2021-12-06T16:07:37.554121Z"},"id":"eec3ddf6","papermill":{"duration":22.676193,"end_time":"2021-12-06T16:15:25.440006","exception":false,"start_time":"2021-12-06T16:15:02.763813","status":"completed"},"tags":[],"colab":{"referenced_widgets":["e976baba7e8a4b1cb37b7e5672571439","49b43e47bf7141d0b81ff556c0392b00","6b3e23ba968446e6b667db1953974661","18c0def413474407b23559bfd6078bbb"]},"outputId":"c5701e64-a43c-49a6-e297-2f8b29689880"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e976baba7e8a4b1cb37b7e5672571439","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49b43e47bf7141d0b81ff556c0392b00","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b3e23ba968446e6b667db1953974661","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18c0def413474407b23559bfd6078bbb","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_ds = IndoMLDataset(AVAILABLE_PRETRAINED_MODELS[config.MODEL_INDEX], train_df.Sentence, train_df.Relation)\n","valid_ds = IndoMLDataset(AVAILABLE_PRETRAINED_MODELS[config.MODEL_INDEX], valid_df.Sentence, valid_df.Relation)\n","test_ds = IndoMLTestDataset(AVAILABLE_PRETRAINED_MODELS[config.MODEL_INDEX], test_df.Sentence, test_df.Id)"]},{"cell_type":"code","execution_count":null,"id":"c38f3f87","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:25.477988Z","iopub.status.busy":"2021-12-06T16:15:25.477340Z","iopub.status.idle":"2021-12-06T16:15:25.483150Z","shell.execute_reply":"2021-12-06T16:15:25.482697Z","shell.execute_reply.started":"2021-12-06T16:08:00.633105Z"},"id":"c38f3f87","outputId":"97f08442-f266-4325-f599-a4a24013bbc9","papermill":{"duration":0.026662,"end_time":"2021-12-06T16:15:25.483272","exception":false,"start_time":"2021-12-06T16:15:25.456610","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"source":["train_dl = torch.utils.data.DataLoader(\n","    train_ds, batch_size=config.BS, shuffle=True, num_workers=4\n",")\n","valid_dl = torch.utils.data.DataLoader(\n","    valid_ds, batch_size=config.BS, shuffle=False, num_workers=4\n",")\n","test_dl = torch.utils.data.DataLoader(\n","    test_ds, batch_size=config.BS, shuffle=False, num_workers=4\n",")"]},{"cell_type":"code","execution_count":null,"id":"f857cd2f","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:15:25.572393Z","iopub.status.busy":"2021-12-06T16:15:25.570561Z","iopub.status.idle":"2021-12-06T16:16:12.840993Z","shell.execute_reply":"2021-12-06T16:16:12.841424Z","shell.execute_reply.started":"2021-12-06T16:08:00.644234Z"},"id":"f857cd2f","outputId":"6d4db972-81d7-43d1-f183-30eebaf6fde4","papermill":{"duration":47.341877,"end_time":"2021-12-06T16:16:12.841579","exception":false,"start_time":"2021-12-06T16:15:25.499702","status":"completed"},"tags":[],"colab":{"referenced_widgets":["ed38c56c6ad34f37a0b2e7b8a2b75bce"]}},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting run ...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed38c56c6ad34f37a0b2e7b8a2b75bce","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["IndoML(\n","  (roberta): XLMRobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.4, inplace=False)\n","  (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (classifier): Linear(in_features=768, out_features=25, bias=True)\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Starting run ...\")\n","model = IndoML(name=AVAILABLE_PRETRAINED_MODELS[config.MODEL_INDEX])\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"01b5a9c2","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:16:12.883693Z","iopub.status.busy":"2021-12-06T16:16:12.883108Z","iopub.status.idle":"2021-12-06T16:16:12.885845Z","shell.execute_reply":"2021-12-06T16:16:12.886286Z","shell.execute_reply.started":"2021-12-06T16:08:48.101000Z"},"id":"01b5a9c2","outputId":"64de9c79-3220-4dfa-a911-a55d76293ece","papermill":{"duration":0.026028,"end_time":"2021-12-06T16:16:12.886438","exception":false,"start_time":"2021-12-06T16:16:12.860410","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear(in_features=768, out_features=25, bias=True)\n","done loading model\n","Training on 12051 samples\n","Evaluating on 1340 samples\n"]}],"source":["print(model.classifier)\n","print(\"done loading model\")\n","print(f\"Training on {len(train_ds)} samples\")\n","print(f\"Evaluating on {len(valid_ds)} samples\")"]},{"cell_type":"code","execution_count":null,"id":"600dacdd","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:16:12.932558Z","iopub.status.busy":"2021-12-06T16:16:12.931879Z","iopub.status.idle":"2021-12-06T16:16:13.153580Z","shell.execute_reply":"2021-12-06T16:16:13.153067Z","shell.execute_reply.started":"2021-12-06T16:12:53.378944Z"},"id":"600dacdd","papermill":{"duration":0.248872,"end_time":"2021-12-06T16:16:13.153738","exception":false,"start_time":"2021-12-06T16:16:12.904866","status":"completed"},"tags":[]},"outputs":[],"source":["num_train_steps = int(len(train_ds) / int(config.BS))\n","optimizer = torch.optim.AdamW(\n","    [\n","        {\"params\": model.roberta.parameters(), \"lr\": float(5e-6)},\n","        {\n","            \"params\": [\n","                param\n","                for name, param in model.named_parameters()\n","                if \"roberta\" not in name\n","            ],\n","            \"lr\": float(1e-3),\n","        },\n","    ],\n","    lr=float(1e-3),\n","    weight_decay=0,\n",")\n","\n","scheduler = transformers.get_cosine_schedule_with_warmup(\n","    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps * int(config.EPOCH)\n",")\n","\n","scaler = torch.cuda.amp.GradScaler(enabled=True)"]},{"cell_type":"code","execution_count":null,"id":"d10ac973","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:16:13.195729Z","iopub.status.busy":"2021-12-06T16:16:13.194916Z","iopub.status.idle":"2021-12-06T16:16:13.903175Z","shell.execute_reply":"2021-12-06T16:16:13.902188Z","shell.execute_reply.started":"2021-12-06T16:12:53.544626Z"},"id":"d10ac973","papermill":{"duration":0.73064,"end_time":"2021-12-06T16:16:13.903350","exception":false,"start_time":"2021-12-06T16:16:13.172710","status":"completed"},"tags":[]},"outputs":[],"source":["!mkdir indoout"]},{"cell_type":"code","execution_count":null,"id":"87b1a9a6","metadata":{"execution":{"iopub.execute_input":"2021-12-06T16:16:13.953170Z","iopub.status.busy":"2021-12-06T16:16:13.952541Z","iopub.status.idle":"2021-12-06T17:24:06.309075Z","shell.execute_reply":"2021-12-06T17:24:06.309536Z"},"id":"87b1a9a6","outputId":"1674e32c-868c-4a98-bc7c-0cd03a165589","papermill":{"duration":4072.385805,"end_time":"2021-12-06T17:24:06.309702","exception":false,"start_time":"2021-12-06T16:16:13.923897","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["0:   1%|          | 12/1507 [00:04<06:22,  3.91it/s, Loss=0.4017, ACC=0.0729, F1=0.0918]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:122: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n","0: 100%|██████████| 1507/1507 [06:16<00:00,  4.00it/s, Loss=0.3621, ACC=0.3930, F1=0.3931]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=0, acc = 0.5276119402985074, F1 = 0.5276119402985074\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_0.csv\n"]},{"name":"stderr","output_type":"stream","text":["1: 100%|██████████| 1507/1507 [06:16<00:00,  4.00it/s, Loss=0.3368, ACC=0.5934, F1=0.5935]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=1, acc = 0.641044776119403, F1 = 0.641044776119403\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_1.csv\n"]},{"name":"stderr","output_type":"stream","text":["2: 100%|██████████| 1507/1507 [06:16<00:00,  4.00it/s, Loss=0.3234, ACC=0.6995, F1=0.6996]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=2, acc = 0.7276119402985075, F1 = 0.7276119402985076\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_2.csv\n"]},{"name":"stderr","output_type":"stream","text":["3: 100%|██████████| 1507/1507 [06:17<00:00,  3.99it/s, Loss=0.3166, ACC=0.7540, F1=0.7541]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=3, acc = 0.7626865671641792, F1 = 0.7626865671641793\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_3.csv\n"]},{"name":"stderr","output_type":"stream","text":["4: 100%|██████████| 1507/1507 [06:17<00:00,  4.00it/s, Loss=0.3119, ACC=0.7912, F1=0.7913]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=4, acc = 0.8082089552238806, F1 = 0.8082089552238807\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_4.csv\n"]},{"name":"stderr","output_type":"stream","text":["5: 100%|██████████| 1507/1507 [06:16<00:00,  4.01it/s, Loss=0.3057, ACC=0.8416, F1=0.8416]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=5, acc = 0.8544776119402985, F1 = 0.8544776119402986\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_5.csv\n"]},{"name":"stderr","output_type":"stream","text":["6: 100%|██████████| 1507/1507 [06:15<00:00,  4.02it/s, Loss=0.3024, ACC=0.8679, F1=0.8679]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=6, acc = 0.8522388059701492, F1 = 0.8522388059701492\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_6.csv\n"]},{"name":"stderr","output_type":"stream","text":["7: 100%|██████████| 1507/1507 [06:15<00:00,  4.02it/s, Loss=0.3008, ACC=0.8807, F1=0.8807]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=7, acc = 0.8634328358208955, F1 = 0.8634328358208955\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_7.csv\n"]},{"name":"stderr","output_type":"stream","text":["8: 100%|██████████| 1507/1507 [06:15<00:00,  4.01it/s, Loss=0.3000, ACC=0.8871, F1=0.8872]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=8, acc = 0.8656716417910447, F1 = 0.8656716417910447\n"]},{"name":"stderr","output_type":"stream","text":["                                                 \r"]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_8.csv\n"]},{"name":"stderr","output_type":"stream","text":["9: 100%|██████████| 1507/1507 [06:15<00:00,  4.01it/s, Loss=0.2998, ACC=0.8891, F1=0.8892]\n","                                                 \r"]},{"name":"stdout","output_type":"stream","text":["epoch=9, acc = 0.8686567164179104, F1 = 0.8686567164179104\n"]},{"name":"stderr","output_type":"stream","text":["                                                 "]},{"name":"stdout","output_type":"stream","text":["File saved in ./indoout/submission_9.csv\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["for epoch in range(config.EPOCH):\n","    train_loop_fn(\n","        train_dl,\n","        model,\n","        optimizer,\n","        device,\n","        scheduler=scheduler,\n","        epoch=epoch,\n","        scaler=scaler,\n","    )\n","    o, t = eval_loop_fn(valid_dl, model, device)\n","    y_true = np.array(t)\n","    y_pred = o\n","    auc = accuracy_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred, average=\"micro\")\n","\n","    print(f\"epoch={epoch}, acc = {auc}, F1 = {f1}\")\n","    preds, ids = pred_loop_fn(test_dl, model, device)\n","    result_df = pd.DataFrame()\n","    result_df[\"Id\"] = ids\n","    result_df[\"Relation\"] = preds\n","    result_df.Relation = result_df.Relation.apply(lambda x: ID2LAB[x])\n","    result_df.to_csv(f\"./indoout/submission_{epoch}.csv\", index=None)\n","    print(f\"File saved in ./indoout/submission_{epoch}.csv\")"]},{"cell_type":"code","execution_count":null,"id":"442ab91c","metadata":{"execution":{"iopub.execute_input":"2021-12-06T17:24:23.774557Z","iopub.status.busy":"2021-12-06T17:24:23.770914Z","iopub.status.idle":"2021-12-06T17:24:23.780037Z","shell.execute_reply":"2021-12-06T17:24:23.779520Z"},"id":"442ab91c","papermill":{"duration":8.794979,"end_time":"2021-12-06T17:24:23.780174","exception":false,"start_time":"2021-12-06T17:24:14.985195","status":"completed"},"tags":[]},"outputs":[],"source":["result_df.to_csv(f\"./submission.csv\", index=None)"]},{"cell_type":"code","execution_count":null,"id":"ba783a1f","metadata":{"papermill":{"duration":8.737891,"end_time":"2021-12-06T17:24:41.759721","exception":false,"start_time":"2021-12-06T17:24:33.021830","status":"completed"},"tags":[],"id":"ba783a1f"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":4203.085713,"end_time":"2021-12-06T17:24:53.638780","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-12-06T16:14:50.553067","version":"2.3.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{}},"colab":{"name":"IndoRE-relation-extraction-challenge.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}